                                                                                                                     â”‚
â”‚                                How the TokenSubsystem Code Works - Complete Breakdown                                â”‚
â”‚                                                                                                                      â”‚
â”‚                                               ğŸ—ï¸ Architecture Overview                                                â”‚
â”‚                                                                                                                      â”‚
â”‚ The TokenSubsystem acts as a wrapper/adapter pattern around the standard LlamaTokenizer. It provides:                â”‚
â”‚                                                                                                                      â”‚
â”‚  1 Backward compatibility with existing XrayGPT code                                                                 â”‚
â”‚  2 Extended functionality for custom tokenization                                                                    â”‚
â”‚  3 Unified interface for all tokenization operations                                                                 â”‚
â”‚                                                                                                                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                        ğŸ“‹ Component-by-Component Explanation                                         â”‚
â”‚                                                                                                                      â”‚
â”‚                                             1. Initialization (__init__)                                             â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  def __init__(self, llama_model_path):                                                                               â”‚
â”‚      # Core tokenizer setup                                                                                          â”‚
â”‚      self.tokenizer = LlamaTokenizer.from_pretrained(llama_model_path, use_fast=False)                               â”‚
â”‚      self.tokenizer.pad_token = self.tokenizer.eos_token                                                             â”‚
â”‚                                                                                                                      â”‚
â”‚      # Attribute exposure for compatibility                                                                          â”‚
â”‚      self.pad_token = self.tokenizer.pad_token                                                                       â”‚
â”‚      self.eos_token = self.tokenizer.eos_token                                                                       â”‚
â”‚      # ... more attributes                                                                                           â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ What happens here:                                                                                                   â”‚
â”‚                                                                                                                      â”‚
â”‚  â€¢ Loads the base LlamaTokenizer from the pretrained model path                                                      â”‚
â”‚  â€¢ Sets pad_token = eos_token (common practice for models without explicit pad tokens)                               â”‚
â”‚  â€¢ Exposes tokenizer attributes directly on the TokenSubsystem instance                                              â”‚
â”‚  â€¢ Creates compatibility layer so existing code doesn't break                                                        â”‚
â”‚                                                                                                                      â”‚
â”‚ Why this design:                                                                                                     â”‚
â”‚                                                                                                                      â”‚
â”‚  â€¢ Original code accessed tokenizer.pad_token_id directly                                                            â”‚
â”‚  â€¢ Now it can access token_subsystem.pad_token_id the same way                                                       â”‚
â”‚  â€¢ No need to change calling code throughout XrayGPT                                                                 â”‚
â”‚                                                                                                                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                       2. Dynamic Attribute Access (Properties)                                       â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  @property                                                                                                           â”‚
â”‚  def padding_side(self):                                                                                             â”‚
â”‚      """Get padding side from underlying tokenizer"""                                                                â”‚
â”‚      return self.tokenizer.padding_side                                                                              â”‚
â”‚                                                                                                                      â”‚
â”‚  @padding_side.setter                                                                                                â”‚
â”‚  def padding_side(self, value):                                                                                      â”‚
â”‚      """Set padding side on underlying tokenizer"""                                                                  â”‚
â”‚      self.tokenizer.padding_side = value                                                                             â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ What this does:                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  â€¢ Dynamic attribute forwarding - when you set token_subsystem.padding_side = "right", it actually sets              â”‚
â”‚    tokenizer.padding_side = "right"                                                                                  â”‚
â”‚  â€¢ Real-time synchronization between wrapper and underlying tokenizer                                                â”‚
â”‚                                                                                                                      â”‚
â”‚ Why properties instead of static attributes:                                                                         â”‚
â”‚                                                                                                                      â”‚
â”‚  â€¢ Some tokenizer attributes can change during runtime (like padding_side)                                           â”‚
â”‚  â€¢ Properties ensure changes are always reflected in the underlying tokenizer                                        â”‚
â”‚  â€¢ Maintains state consistency                                                                                       â”‚
â”‚                                                                                                                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                           3. Callable Interface (__call__)                                           â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  def __call__(self, *args, **kwargs):                                                                                â”‚
â”‚      """Make TokenSubsystem callable like the original tokenizer"""                                                  â”‚
â”‚      return self.tokenizer(*args, **kwargs)                                                                          â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ What this enables:                                                                                                   â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  # Both of these work identically:                                                                                   â”‚
â”‚  tokens = tokenizer("Hello world", return_tensors="pt")                                                              â”‚
â”‚  tokens = token_subsystem("Hello world", return_tensors="pt")                                                        â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ How it works:                                                                                                        â”‚
â”‚                                                                                                                      â”‚
â”‚  â€¢ Python magic method __call__ makes the object callable like a function                                            â”‚
â”‚  â€¢ Forwards all arguments directly to the underlying tokenizer                                                       â”‚
â”‚  â€¢ Returns exact same result as calling tokenizer directly                                                           â”‚
â”‚                                                                                                                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                        4. Method Forwarding (decode, encode)                                         â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  def decode(self, *args, **kwargs):                                                                                  â”‚
â”‚      """Expose decode method for compatibility"""                                                                    â”‚
â”‚      return self.tokenizer.decode(*args, **kwargs)                                                                   â”‚
â”‚                                                                                                                      â”‚
â”‚  def encode(self, *args, **kwargs):                                                                                  â”‚
â”‚      """Expose encode method for compatibility"""                                                                    â”‚
â”‚      return self.tokenizer.encode(*args, **kwargs)                                                                   â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ Purpose:                                                                                                             â”‚
â”‚                                                                                                                      â”‚
â”‚  â€¢ Method delegation pattern - forwards calls to underlying tokenizer                                                â”‚
â”‚  â€¢ Maintains exact same API as original tokenizer                                                                    â”‚
â”‚  â€¢ Enables drop-in replacement without changing existing code                                                        â”‚
â”‚                                                                                                                      â”‚
â”‚ Usage examples:                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  # Decoding token IDs back to text                                                                                   â”‚
â”‚  text = token_subsystem.decode([1, 2, 3, 4], skip_special_tokens=True)                                               â”‚
â”‚                                                                                                                      â”‚
â”‚  # Encoding text to token IDs                                                                                        â”‚
â”‚  token_ids = token_subsystem.encode("Hello world")                                                                   â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                    5. Custom Tokenization Method (text_to_tokens)                                    â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  def text_to_tokens(self, text, add_bos=True, max_length=128):                                                       â”‚
â”‚      # Standard tokenization                                                                                         â”‚
â”‚      tokens = self.tokenizer(                                                                                        â”‚
â”‚          text,                                                                                                       â”‚
â”‚          return_tensors="pt",      # Return PyTorch tensors                                                          â”‚
â”‚          padding="longest",        # Pad to longest sequence in batch                                                â”‚
â”‚          truncation=True,         # Truncate if too long                                                             â”‚
â”‚          max_length=max_length,   # Maximum sequence length                                                          â”‚
â”‚          add_special_tokens=False # Don't add BOS/EOS automatically                                                  â”‚
â”‚      )                                                                                                               â”‚
â”‚                                                                                                                      â”‚
â”‚      # Custom BOS token handling                                                                                     â”‚
â”‚      if add_bos:                                                                                                     â”‚
â”‚          bos = torch.full(                                                                                           â”‚
â”‚              (len(text), 1),                    # Shape: [batch_size, 1]                                             â”‚
â”‚              self.tokenizer.bos_token_id,       # Fill with BOS token ID                                             â”‚
â”‚              dtype=tokens.input_ids.dtype       # Match existing tensor type                                         â”‚
â”‚          )                                                                                                           â”‚
â”‚          # Concatenate BOS to the beginning                                                                          â”‚
â”‚          tokens.input_ids = torch.cat([bos, tokens.input_ids], dim=1)                                                â”‚
â”‚          tokens.attention_mask = torch.cat(                                                                          â”‚
â”‚              [torch.ones_like(bos), tokens.attention_mask], dim=1                                                    â”‚
â”‚          )                                                                                                           â”‚
â”‚      return tokens                                                                                                   â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ Step-by-step breakdown:                                                                                              â”‚
â”‚                                                                                                                      â”‚
â”‚  1 Standard Tokenization:                                                                                            â”‚
â”‚     â€¢ Converts text to token IDs                                                                                     â”‚
â”‚     â€¢ Handles padding and truncation                                                                                 â”‚
â”‚     â€¢ Returns PyTorch tensors                                                                                        â”‚
â”‚  2 Custom BOS Handling:                                                                                              â”‚
â”‚     â€¢ Creates BOS token tensor manually                                                                              â”‚
â”‚     â€¢ Concatenates to beginning of sequences                                                                         â”‚
â”‚     â€¢ Updates attention masks accordingly                                                                            â”‚
â”‚  3 Return Format:                                                                                                    â”‚
â”‚     â€¢ Returns tokenizer output with .input_ids and .attention_mask                                                   â”‚
â”‚     â€¢ Compatible with transformer models                                                                             â”‚
â”‚                                                                                                                      â”‚
â”‚ Example usage:                                                                                                       â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  texts = ["Hello world", "How are you?"]                                                                             â”‚
â”‚  tokens = token_subsystem.text_to_tokens(texts, add_bos=True, max_length=64)                                         â”‚
â”‚  # tokens.input_ids: [[1, 15043, 3186], [1, 1128, 526, 366, 29973]]                                                  â”‚
â”‚  # tokens.attention_mask: [[1, 1, 1], [1, 1, 1, 1, 1]]                                                               â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                          ğŸ”„ How It Integrates with XrayGPT                                           â”‚
â”‚                                                                                                                      â”‚
â”‚                                                  In MiniGPT4 Model:                                                  â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚  # Initialization                                                                                                    â”‚
â”‚  self.token_subsystem = TokenSubsystem(llama_model)                                                                  â”‚
â”‚  self.llama_tokenizer = self.token_subsystem  # Backward compatibility                                               â”‚
â”‚                                                                                                                      â”‚
â”‚  # Usage in forward pass                                                                                             â”‚
â”‚  tokens = self.token_subsystem(text, return_tensors="pt", padding="longest")                                         â”‚
â”‚                                                                                                                      â”‚
â”‚  # Usage in inference                                                                                                â”‚
â”‚  output_text = self.token_subsystem.decode(output_tokens, add_special_tokens=False)                                  â”‚
â”‚                                                                                                                      â”‚
â”‚                                                                                                                      â”‚
â”‚                                                    Key Benefits:                                                     â”‚
â”‚                                                                                                                      â”‚
â”‚  1 ğŸ”Œ Drop-in Replacement: Existing code works without modification                                                  â”‚
â”‚  2 ğŸ›ï¸ Extended Control: Custom tokenization logic when needed                                                         â”‚
â”‚  3 ğŸ”„ Backward Compatible: All original tokenizer methods still work                                                 â”‚
â”‚  4 âš¡ Performance: No overhead - just forwarding calls                                                               â”‚
â”‚  5 ğŸ§© Modular: Easy to extend with more custom logic                                                                 â”‚
â”‚                                                                                                                      â”‚
â”‚                                               ğŸ¯ Design Patterns Used                                                â”‚
â”‚                                                                                                                      â”‚
â”‚  1 Wrapper Pattern: TokenSubsystem wraps LlamaTokenizer                                                              â”‚
â”‚  2 Adapter Pattern: Adapts tokenizer interface for XrayGPT needs                                                     â”‚
â”‚  3 Delegation Pattern: Forwards method calls to underlying tokenizer                                                 â”‚
â”‚  4 Property Pattern: Dynamic attribute access and modification                                                       â”‚
â”‚                                                                                                                      â”‚
â”‚ This design allows XrayGPT to maintain its existing tokenization workflow while providing hooks for custom           â”‚
â”‚ tokenization logic when needed.        
